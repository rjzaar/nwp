# NWP GitLab CI/CD Configuration
#
# Complete CI/CD pipeline for NWP-managed Drupal sites
# Based on NWP roadmap P20 (GitLab CI Pipeline)
#
# Pipeline Stages:
#   database - Fetch/cache production database for testing
#   build    - Install dependencies, prepare environment
#   deploy   - Deploy to staging/production environments
#
# Features:
# - Nightly database caching for faster builds
# - Production database import with sanitization
# - Automatic composer and npm builds
# - Drupal deployment (updb, cim, cr)
# - Environment-specific deployments
# - Test coverage reporting
# - Artifact management

stages:
  - lint
  - test
  - database
  - build
  - security
  - deploy
  - preview
  - e2e

################################################################################
# Global Variables
################################################################################

variables:
  # Site configuration
  SITE_NAME: ${CI_PROJECT_NAME}
  PHP_VERSION: "8.2"

  # Database configuration
  MYSQL_ROOT_PASSWORD: root
  MYSQL_DATABASE: drupal
  MYSQL_USER: drupal
  MYSQL_PASSWORD: drupal

  # Drupal configuration
  SIMPLETEST_DB: mysql://drupal:drupal@database/drupal
  SIMPLETEST_BASE_URL: http://web:8080
  BROWSERTEST_OUTPUT_DIRECTORY: /var/www/html/web/sites/simpletest/browser_output

  # Composer configuration
  COMPOSER_ALLOW_SUPERUSER: "1"
  COMPOSER_MEMORY_LIMIT: "-1"

  # DDEV configuration
  DDEV_NONINTERACTIVE: "true"

################################################################################
# Default Configuration
################################################################################

default:
  # Use DDEV-compatible image
  image: ddev/ddev-webserver:latest

  # Allow pipeline interruption for newer runs
  interruptible: true

  # Retry on infrastructure failures
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
      - scheduler_failure

################################################################################
# Cache Configuration
################################################################################

# Cache composer dependencies globally
cache:
  key: "${CI_COMMIT_REF_SLUG}-composer"
  paths:
    - vendor/
    - web/core/
    - web/modules/contrib/
    - web/themes/contrib/
    - node_modules/
  policy: pull

################################################################################
# Workflow Rules
################################################################################

workflow:
  rules:
    # Run on merge request events
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    # Run on scheduled pipelines (nightly database cache)
    - if: $CI_PIPELINE_SOURCE == "schedule"
    # Prevent duplicate pipelines for MRs
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    # Run on branch pushes
    - if: $CI_COMMIT_BRANCH

################################################################################
# LINT STAGE
# Fast syntax and style validation
################################################################################

# Bash syntax validation
lint:bash:
  stage: lint
  image: ubuntu:22.04
  script:
    - apt-get update -qq && apt-get install -y -qq bash
    - echo "Validating bash syntax for all scripts and libraries..."
    - find scripts/commands lib -name "*.sh" -type f -exec bash -n {} \;
  rules:
    - if: $CI_PIPELINE_SOURCE == "push"
  tags:
    - nwp

################################################################################
# TEST STAGE
# Unit and integration tests
################################################################################

# Unit tests (BATS)
test:unit:
  stage: test
  image: ubuntu:22.04
  before_script:
    - apt-get update -qq && apt-get install -y -qq bats git
  script:
    - echo "Running BATS unit tests..."
    - bats tests/unit/
  artifacts:
    when: always
    reports:
      junit: tests/unit/results.xml
    paths:
      - tests/unit/results.xml
    expire_in: 1 week
  rules:
    - if: $CI_PIPELINE_SOURCE == "push"
  tags:
    - nwp

# Integration tests (BATS) - syntax validation only in CI
test:integration:
  stage: test
  image: ubuntu:22.04
  before_script:
    - apt-get update -qq && apt-get install -y -qq bats git
  script:
    - echo "Running BATS integration tests (non-DDEV tests only)..."
    - bats tests/integration/06-scripts-validation.bats
  artifacts:
    when: always
    reports:
      junit: tests/integration/results.xml
    paths:
      - tests/integration/results.xml
    expire_in: 1 week
  rules:
    - if: $CI_PIPELINE_SOURCE == "push"
  tags:
    - nwp
  allow_failure: false

# NWP Verification System (P50)
# Runs machine verification checks and generates badges
test:verification:
  stage: test
  image: ubuntu:22.04
  before_script:
    - apt-get update -qq && apt-get install -y -qq bash git jq bc
  script:
    - echo "Running NWP verification checks..."
    - ./scripts/commands/verify.sh ci --depth=basic --export-json
  artifacts:
    when: always
    paths:
      - .badges.json
      - .logs/verification/
    expire_in: 30 days
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  tags:
    - nwp
  allow_failure: true

################################################################################
# DATABASE STAGE
# Fetch and cache production database for testing
################################################################################

# Nightly database caching job
# Runs on schedule to fetch and cache production database
# Artifacts expire after 1 day and are used by other jobs
database:nightly:
  stage: database
  rules:
    # Only run on scheduled pipelines (configure schedule in GitLab)
    - if: $CI_PIPELINE_SOURCE == "schedule"
  script:
    - echo "Fetching and caching production database..."
    - ./scripts/ci/fetch-db.sh --sanitize
  artifacts:
    paths:
      - .data/db.sql.gz
    expire_in: 1 day
  tags:
    - nwp
  # Allow failure to not block other scheduled jobs
  allow_failure: true

# Database job for regular builds
# Uses cached database from nightly job if available
# Falls back to fetching fresh database if cache is stale
database:
  stage: database
  rules:
    # Skip on scheduled pipelines (nightly job handles this)
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: never
    # Run on all other pipelines
    - when: on_success
  script:
    - echo "Checking for cached database..."
    # Try to use cached database from nightly job
    - |
      if [ -f .data/db.sql.gz ]; then
        echo "Using cached database from nightly job"
      else
        echo "No cache available, fetching fresh database..."
        ./scripts/ci/fetch-db.sh --sanitize
      fi
  artifacts:
    paths:
      - .data/db.sql.gz
    expire_in: 1 hour
  cache:
    # Pull cache only
    policy: pull
  tags:
    - nwp
  # Allow failure for non-blocking database issues
  allow_failure: true

################################################################################
# BUILD STAGE
# Install dependencies, build assets, import database, run deployment
################################################################################

build:
  stage: build
  needs: ["database"]
  script:
    - echo "Starting build process for ${SITE_NAME}..."

    # Install system dependencies for DDEV
    - apt-get update -qq
    - apt-get install -y -qq docker.io docker-compose

    # Run the build script
    - ./scripts/ci/build.sh

    # Show build information
    - echo "Build completed successfully"
    - ddev describe || true

  artifacts:
    paths:
      - vendor/
      - web/
      - node_modules/
      - .logs/
    reports:
      dotenv: build.env
    expire_in: 1 hour
  cache:
    # Update cache with new dependencies
    key: "${CI_COMMIT_REF_SLUG}-composer"
    paths:
      - vendor/
      - web/core/
      - web/modules/contrib/
      - web/themes/contrib/
      - node_modules/
    policy: pull-push
  tags:
    - nwp
  timeout: 30 minutes

# Coverage check job
# Validates test coverage meets threshold
coverage:
  stage: build
  needs: ["build"]
  script:
    - echo "Checking code coverage..."

    # Check if coverage report exists
    - |
      if [ -f .logs/coverage/clover.xml ]; then
        ./scripts/ci/check-coverage.sh 80 .logs/coverage/clover.xml
      else
        echo "No coverage report found, skipping coverage check"
        exit 0
      fi
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: .logs/coverage/cobertura.xml
    paths:
      - .logs/coverage/
    expire_in: 1 week
  coverage: '/^\s*Lines:\s*\d+.\d+\%/'
  tags:
    - nwp
  allow_failure: true

################################################################################
# SECURITY STAGE
# Security scanning for vulnerabilities and malicious code
################################################################################

# Security scan job
# Runs automated security checks on code and dependencies
security:scan:
  stage: security
  needs: ["build"]
  rules:
    # Run on all branches
    - when: on_success
  script:
    - echo "Starting security scans..."

    # Dependency audit - check for known vulnerabilities
    - echo "=== Composer Security Audit ==="
    - |
      if [ -f composer.json ]; then
        composer audit || echo "WARNING: Vulnerabilities found in dependencies"
      else
        echo "No composer.json found, skipping composer audit"
      fi

    # NPM audit if package.json exists
    - echo ""
    - echo "=== NPM Security Audit ==="
    - |
      if [ -f package.json ]; then
        npm audit --audit-level=high 2>/dev/null || echo "WARNING: Vulnerabilities found in npm packages"
      else
        echo "No package.json found, skipping npm audit"
      fi

    # Secret detection patterns
    - echo ""
    - echo "=== Secret Detection ==="
    - |
      echo "Scanning for exposed secrets..."
      secrets_found=0

      # API keys and tokens
      if grep -rn --include="*.php" --include="*.sh" --include="*.js" --include="*.yml" \
          -E "(api_key|api_token|access_token|secret_key|private_key)\s*=\s*['\"][^'\"]{20,}" \
          . 2>/dev/null | grep -v ".gitlab-ci.yml" | grep -v "example" | grep -v "test"; then
        echo "WARNING: Potential hardcoded secrets found"
        secrets_found=1
      fi

      # AWS keys
      if grep -rn --include="*.php" --include="*.sh" --include="*.js" --include="*.yml" \
          -E "AKIA[0-9A-Z]{16}" . 2>/dev/null; then
        echo "WARNING: Potential AWS keys found"
        secrets_found=1
      fi

      # Private keys
      if grep -rn --include="*" -l "BEGIN.*PRIVATE KEY" . 2>/dev/null | grep -v "test" | grep -v "example"; then
        echo "WARNING: Private keys found in repository"
        secrets_found=1
      fi

      if [ $secrets_found -eq 0 ]; then
        echo "OK: No secrets detected"
      fi

    # Suspicious pattern detection
    - echo ""
    - echo "=== Suspicious Pattern Scan ==="
    - |
      echo "Scanning for suspicious code patterns..."
      suspicious_found=0

      # Code execution patterns
      if grep -rn --include="*.php" --include="*.sh" \
          -E "(eval|base64_decode|exec|system|passthru|shell_exec|proc_open)\s*\(" \
          . 2>/dev/null | grep -v ".gitlab-ci.yml" | grep -v "test" | grep -v "vendor"; then
        echo "WARNING: Potentially dangerous code execution patterns found"
        suspicious_found=1
      fi

      # Obfuscation patterns
      if grep -rn --include="*.php" --include="*.js" \
          -E "(chr\([0-9]+\)|\\\\x[0-9a-f]{2}){5,}" \
          . 2>/dev/null | grep -v "vendor" | grep -v "test"; then
        echo "WARNING: Potential code obfuscation found"
        suspicious_found=1
      fi

      if [ $suspicious_found -eq 0 ]; then
        echo "OK: No suspicious patterns detected"
      fi

    # File permission checks
    - echo ""
    - echo "=== File Permission Check ==="
    - |
      echo "Checking for overly permissive files..."
      if find . -type f -perm -002 2>/dev/null | grep -v ".git" | head -5; then
        echo "WARNING: World-writable files found"
      else
        echo "OK: No world-writable files"
      fi

    # External URL detection in new code
    - echo ""
    - echo "=== External URL Check ==="
    - |
      if [ "$CI_PIPELINE_SOURCE" == "merge_request_event" ]; then
        echo "Checking for new external URLs in MR..."
        git fetch origin $CI_MERGE_REQUEST_TARGET_BRANCH_NAME 2>/dev/null || true
        if git diff origin/$CI_MERGE_REQUEST_TARGET_BRANCH_NAME..HEAD 2>/dev/null | \
            grep "^+" | grep -oE 'https?://[^"'\'')\s]+' | \
            grep -v "drupal.org" | grep -v "github.com" | grep -v "gitlab.com" | head -10; then
          echo "INFO: New external URLs detected - review required"
        else
          echo "OK: No new external URLs"
        fi
      else
        echo "Skipping (not a merge request)"
      fi

    - echo ""
    - echo "=== Security Scan Complete ==="

  artifacts:
    reports:
      # Store security findings
      junit: .logs/security-report.xml
    paths:
      - .logs/security/
    expire_in: 1 week
    when: always
  tags:
    - nwp
  # Don't block pipeline on security warnings (review manually)
  allow_failure: true

# Security review for merge requests
# Performs scope verification and red flag detection
security:review:
  stage: security
  needs: ["build"]
  rules:
    # Only run for merge requests
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - echo "=== Merge Request Security Review ==="
    - echo ""
    - echo "MR Title: $CI_MERGE_REQUEST_TITLE"
    - echo "Source Branch: $CI_MERGE_REQUEST_SOURCE_BRANCH_NAME"
    - echo "Target Branch: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME"
    - echo ""

    # Fetch target branch for comparison
    - git fetch origin $CI_MERGE_REQUEST_TARGET_BRANCH_NAME

    # File count analysis
    - echo "=== Scope Analysis ==="
    - |
      files_changed=$(git diff --name-only origin/$CI_MERGE_REQUEST_TARGET_BRANCH_NAME..HEAD | wc -l)
      echo "Files changed: $files_changed"

      if [ $files_changed -gt 20 ]; then
        echo "INFO: Large changeset - thorough review recommended"
      fi

    # Lines changed
    - git diff --stat origin/$CI_MERGE_REQUEST_TARGET_BRANCH_NAME..HEAD | tail -1

    # Sensitive file modifications
    - echo ""
    - echo "=== Sensitive File Check ==="
    - |
      if git diff --name-only origin/$CI_MERGE_REQUEST_TARGET_BRANCH_NAME..HEAD | \
          grep -E '(settings\.php|\.env|\.htaccess|nginx\.conf|auth|login|password|credential|secret|token|\.gitlab-ci)'; then
        echo "WARNING: Sensitive files modified - requires additional review"
      else
        echo "OK: No sensitive files modified"
      fi

    # New dependencies
    - echo ""
    - echo "=== Dependency Changes ==="
    - |
      if git diff origin/$CI_MERGE_REQUEST_TARGET_BRANCH_NAME..HEAD -- composer.json package.json 2>/dev/null | grep "^\+" | grep -v "^\+\+\+"; then
        echo "INFO: Dependencies modified - review required"
      else
        echo "OK: No dependency changes"
      fi

    # Scope verification hint
    - echo ""
    - echo "=== Scope Verification ==="
    - echo "Review: Does the diff match the MR title and description?"
    - echo "Red flags:"
    - echo "  - Large changeset for small fix"
    - echo "  - Unrelated file modifications"
    - echo "  - New external dependencies"
    - echo "  - Authentication/security changes"

  artifacts:
    paths:
      - .logs/mr-review.txt
    expire_in: 1 week
  tags:
    - nwp
  allow_failure: true

################################################################################
# DEPLOY STAGE
# Deploy to staging and production environments
################################################################################

# Deploy to staging environment
# Runs on develop branch, manual trigger required
deploy:staging:
  stage: deploy
  needs: ["build"]
  rules:
    # Deploy to staging on develop branch (manual)
    - if: $CI_COMMIT_BRANCH == "develop"
      when: manual
    # Also allow manual deploy from main branch to staging
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: manual
  script:
    - echo "Deploying to staging environment..."

    # Set up SSH key for deployment
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - echo "$STAGING_SSH_KEY" | base64 -d > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - ssh-keyscan -H $STAGING_HOST >> ~/.ssh/known_hosts

    # Deploy to staging using rsync
    - |
      rsync -avz \
        --exclude='.git' \
        --exclude='.ddev' \
        --exclude='node_modules' \
        --exclude='.data' \
        --exclude='sitebackups' \
        --delete \
        ./ ${STAGING_USER}@${STAGING_HOST}:${STAGING_PATH}/

    # Run deployment commands on staging server
    - |
      ssh ${STAGING_USER}@${STAGING_HOST} "
        cd ${STAGING_PATH}
        ddev drush deploy -y
        ddev drush cr
        echo 'Staging deployment completed'
      "
  environment:
    name: staging
    url: https://staging.${SITE_NAME}.${BASE_DOMAIN}
    on_stop: stop:staging
  tags:
    - nwp
  only:
    variables:
      # Only run if staging variables are configured
      - $STAGING_HOST
      - $STAGING_USER
      - $STAGING_PATH

# Stop staging environment
stop:staging:
  stage: deploy
  rules:
    - if: $CI_COMMIT_BRANCH == "develop"
      when: manual
  script:
    - echo "Stopping staging environment..."
    - ssh ${STAGING_USER}@${STAGING_HOST} "cd ${STAGING_PATH} && ddev stop"
  environment:
    name: staging
    action: stop
  tags:
    - nwp
  only:
    variables:
      - $STAGING_HOST
      - $STAGING_USER

# Deploy to production environment
# Runs on main/production branch, manual trigger required
# This is the final step and requires explicit approval
deploy:production:
  stage: deploy
  needs: ["build"]
  rules:
    # Deploy to production only on main branch (manual trigger)
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH || $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "production"
      when: manual
  script:
    - echo "Deploying to production environment..."

    # Set up SSH key for deployment
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - echo "$PRODUCTION_SSH_KEY" | base64 -d > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - ssh-keyscan -H $PRODUCTION_HOST >> ~/.ssh/known_hosts

    # Create backup before deployment
    - |
      ssh ${PRODUCTION_USER}@${PRODUCTION_HOST} "
        cd ${PRODUCTION_PATH}
        echo 'Creating backup before deployment...'
        ddev snapshot --name=pre-deploy-${CI_COMMIT_SHORT_SHA}
      "

    # Deploy to production using rsync
    - |
      rsync -avz \
        --exclude='.git' \
        --exclude='.ddev' \
        --exclude='node_modules' \
        --exclude='.data' \
        --exclude='sitebackups' \
        --exclude='web/sites/*/files' \
        --delete \
        ./ ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/

    # Run deployment commands on production server
    - |
      ssh ${PRODUCTION_USER}@${PRODUCTION_HOST} "
        cd ${PRODUCTION_PATH}
        echo 'Running Drupal deployment tasks...'
        ddev drush deploy -y
        ddev drush cr
        echo 'Production deployment completed successfully'
      "

    # Verify deployment
    - |
      ssh ${PRODUCTION_USER}@${PRODUCTION_HOST} "
        cd ${PRODUCTION_PATH}
        ddev drush status
      "
  environment:
    name: production
    url: https://${SITE_NAME}.${BASE_DOMAIN}
  tags:
    - nwp
  # Do not allow failure for production deployments
  allow_failure: false
  only:
    variables:
      # Only run if production variables are configured
      - $PRODUCTION_HOST
      - $PRODUCTION_USER
      - $PRODUCTION_PATH

################################################################################
# CI/CD Variables Required
################################################################################
#
# Configure these in GitLab: Settings > CI/CD > Variables
#
# Database & Build:
#   (none required - uses local database fetch)
#
# Staging Deployment:
#   STAGING_HOST         - Staging server hostname/IP
#   STAGING_USER         - SSH username for staging
#   STAGING_PATH         - Path to site on staging server
#   STAGING_SSH_KEY      - Base64-encoded SSH private key
#   BASE_DOMAIN          - Base domain for environments (e.g., nwpcode.org)
#
# Production Deployment:
#   PRODUCTION_HOST      - Production server hostname/IP
#   PRODUCTION_USER      - SSH username for production
#   PRODUCTION_PATH      - Path to site on production server
#   PRODUCTION_SSH_KEY   - Base64-encoded SSH private key
#   BASE_DOMAIN          - Base domain for production (e.g., example.com)
#
# To encode SSH key for CI/CD variables:
#   cat ~/.ssh/id_rsa | base64 -w 0
#
################################################################################

################################################################################
# Scheduled Pipeline Configuration
################################################################################
#
# To enable nightly database caching:
#
# 1. Go to: Settings > CI/CD > Schedules
# 2. Click "New schedule"
# 3. Configure:
#    - Description: "Nightly database cache"
#    - Interval: "0 2 * * *" (2 AM daily)
#    - Target branch: main
#    - Variables: (none needed)
# 4. Save pipeline schedule
#
# The database:nightly job will run and cache the production database
# for use by builds throughout the next day.
#
################################################################################

################################################################################
# PREVIEW ENVIRONMENTS
# Create isolated preview environments for merge requests
################################################################################

# Deploy preview environment for merge requests
# Creates an isolated DDEV environment for testing PR changes
deploy:preview:
  stage: preview
  needs: ["build"]
  rules:
    # Only run for merge requests
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - echo "Creating preview environment for MR $CI_MERGE_REQUEST_IID..."

    # Install DDEV if not available
    - |
      if ! command -v ddev >/dev/null 2>&1; then
        echo "Installing DDEV..."
        curl -fsSL https://raw.githubusercontent.com/ddev/ddev/master/scripts/install_ddev.sh | bash
      fi

    # Create preview environment
    - ./scripts/ci/create-preview.sh "mr-$CI_MERGE_REQUEST_IID"

    # Get preview URL for artifacts
    - |
      if [ -f .preview-env ]; then
        source .preview-env
        echo "PREVIEW_URL=$PREVIEW_URL" > preview.env
        echo "Preview environment available at: $PREVIEW_URL"
      fi

  environment:
    name: preview/mr-$CI_MERGE_REQUEST_IID
    url: https://mr-$CI_MERGE_REQUEST_IID.ddev.site
    on_stop: cleanup:preview
    auto_stop_in: 1 week
  artifacts:
    reports:
      dotenv: preview.env
    paths:
      - .preview-env
    expire_in: 1 week
  tags:
    - nwp
  allow_failure: false

# Cleanup preview environment
# Runs manually or when MR is closed
cleanup:preview:
  stage: preview
  needs: []
  rules:
    # Manual cleanup for open MRs
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
      allow_failure: true
  script:
    - echo "Cleaning up preview environment for MR $CI_MERGE_REQUEST_IID..."

    # Install DDEV if not available
    - |
      if ! command -v ddev >/dev/null 2>&1; then
        echo "Installing DDEV..."
        curl -fsSL https://raw.githubusercontent.com/ddev/ddev/master/scripts/install_ddev.sh | bash
      fi

    # Cleanup preview environment
    - ./scripts/ci/cleanup-preview.sh "mr-$CI_MERGE_REQUEST_IID" || true

    - echo "Preview environment cleaned up"

  environment:
    name: preview/mr-$CI_MERGE_REQUEST_IID
    action: stop
  tags:
    - nwp
  allow_failure: true

################################################################################
# Usage Examples
################################################################################
#
# Standard workflow:
#   1. Developer pushes to feature branch
#   2. Pipeline runs: database → build
#   3. Developer creates merge request
#   4. Pipeline runs again: database → build → preview
#   5. Preview environment created with unique URL
#   6. Review and test in preview environment
#   7. After merge to develop: manual deploy to staging
#   8. After merge to main: manual deploy to production
#   9. Preview environment auto-cleans up after 1 week
#
# Nightly workflow:
#   1. Scheduled pipeline runs at 2 AM
#   2. database:nightly job fetches and caches DB
#   3. Cache available for all builds during the day
#   4. Next night, cache refreshes
#
# Preview environment workflow:
#   1. Open merge request
#   2. CI creates preview environment (preview/mr-123)
#   3. Access preview at https://mr-123.ddev.site
#   4. Test changes in isolated environment
#   5. Manual cleanup available via GitLab UI
#   6. Auto-cleanup after 1 week of inactivity
#
################################################################################

################################################################################
# E2E STAGE
# End-to-end tests on Linode infrastructure (nightly only)
################################################################################

# E2E: Fresh install test
e2e:fresh-install:
  stage: e2e
  image: ubuntu:22.04
  before_script:
    - apt-get update -qq && apt-get install -y -qq curl git ssh
  script:
    - echo "E2E tests not yet implemented - placeholder job"
    - echo "See tests/e2e/README.md for planned implementation"
    - ./tests/e2e/test-fresh-install.sh || true
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: manual
  timeout: 2h
  tags:
    - nwp
  allow_failure: true
  after_script:
    - echo "Cleanup would run here"

# E2E: Production deployment test
e2e:production:
  stage: e2e
  image: ubuntu:22.04
  script:
    - echo "E2E production tests not yet implemented"
    - echo "Future: Test staging -> production deployment"
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: manual
  timeout: 3h
  tags:
    - nwp
  allow_failure: true

################################################################################
# Pipeline Badges
################################################################################
#
# Add to your README.md:
#
# Pipeline Status:
# ![Pipeline](https://git.${BASE_DOMAIN}/${CI_PROJECT_PATH}/badges/${CI_DEFAULT_BRANCH}/pipeline.svg)
#
# Coverage:
# ![Coverage](https://git.${BASE_DOMAIN}/${CI_PROJECT_PATH}/badges/${CI_DEFAULT_BRANCH}/coverage.svg)
#
################################################################################
